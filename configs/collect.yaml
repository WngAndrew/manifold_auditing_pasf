#default config
# model_name: meta-llama/Meta-Llama-3.2-3B
# layer: 20
# batch_size: 32
# max_length: 256
# torch_dtype: float16
# prompts: data/prompts/prompts_10k.json

# Test config for activation collection with fine-tuned TinyLlama
model_name: meta-llama/Meta-Llama-3-8B-Instruct
layer: 31
batch_size: 64
max_length: 256
torch_dtype: float16

 
prompts: src/data/prompts/prompts_10k.jsonl
